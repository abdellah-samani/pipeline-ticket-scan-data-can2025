# ğŸ† CAN 2025 â€“ Pipeline pour lâ€™ingestion, la transformation et lâ€™analyse des donnÃ©es des scans de billets â€“ CAN 2025

## ğŸ“‹ AperÃ§u du projet
Pipeline complet d'ingestion, transformation et analyse des donnÃ©es **simulÃ©es** de scans de billets pour la Coupe d'Afrique des Nations 2025.

**Auteur** : Abdellah Samani  
**Email** : abdellah.samani.data@gmail.com  
**Date** : Janvier 2026

---

## ğŸ¯ Objectifs
- Centraliser les sources hÃ©tÃ©rogÃ¨nes (bases SQL + fichiers CSV)
- Construire un pipeline fiable, scalable et automatisÃ©
- Produire des donnÃ©es prÃªtes pour l'analyse (gold layer)
- Assurer audit et traÃ§abilitÃ© des donnÃ©es
- DÃ©montrer l'utilisation des services Azure pour un projet complet de data engineering

---

## ğŸ“Š RÃ©sultats
| MÃ©trique | Valeur |
|----------|--------|
| DonnÃ©es traitÃ©es | 1.46 million de scans |
| QualitÃ© donnÃ©es | 99.88% valides |

---

##  Architecture

**Architecture MÃ©daillon :**
Bronze (Parquet) â†’ Silver (Delta) â†’ Gold (Star Schema Delta)


### Stack technique :
- **Ingestion** : Azure Data Factory
- **Transformation** : Azure Databricks (PySpark)
- **Stockage** : Azure Data Lake Gen2
- **Visualisation** : Power BI
- **SÃ©curitÃ©** : Azure Key Vault
- **Format** : Parquet â†’ Delta â†’ Delta



## ğŸ“ Structure du projet

CAN 2025 - Pipeline Data Engineering End-to-End/
â”œâ”€â”€ 01. Source de DonnÃ©es (SQL et CSV)/                # DonnÃ©es utilisÃ©s dans le projet
â”œâ”€â”€ 02. Ingestion (Azure Data Factory Pipeline)/       # Pipelines ADF et configurations
â”œâ”€â”€ 03. Transformation (Azure Databricks Notebooks)/   # Notebooks Databricks
â”œâ”€â”€ 04. Consommation (Power BI Dashboard)              # Fichiers Power BI (capture d'Ã©cran + fichier pbix)
â”œâ”€â”€ 05. Documentation/                                 # Documentation et diagrammes
â”œâ”€â”€ 06. Screenshots/                                   # Captures d'Ã©cran du portail Azure
â””â”€â”€ README.md


## ğŸ”§ Composants principaux

### Ingestion (ADF)
- `pl_to_bronze_parquet` : Pipeline principal d'ingestion
- Configuration dynamique via fichiers CSV

### Transformation (Databricks)
- `01_silver_dimensions_processing` : Nettoyage des dimensions
- `02_silver_fact_tickets_cleaning` : Nettoyage des faits (1.46M lignes)
- `03_silver_fact_tickets_enriching` : Enrichissement des donnÃ©es
- `04_gold_star_schema_creation` : CrÃ©ation du schÃ©ma en Ã©toile

### Consommation (Power BI)
- Dashboard analytique basÃ© sur donnÃ©es batch
- Connexion via Unity Catalog
- KPI : billets scannÃ©s, participation par stade, rÃ©partition par canal

---

## ğŸ“ˆ MÃ©triques de qualitÃ©
- **ComplÃ©tude** : 100% des champs obligatoires
- **ValiditÃ©** : Formats validÃ©s (ticket_id, fan_id, dates)
- **CohÃ©rence** : Relations rÃ©fÃ©rentielles vÃ©rifiÃ©es
- **UnicitÃ©** : Pas de doublons dans les clÃ©s

---

## ğŸ›¡ï¸ SÃ©curitÃ©
- Tous les secrets stockÃ©s dans **Azure Key Vault**
- AccÃ¨s aux donnÃ©es contrÃ´lÃ© et auditÃ©

---


---

## ğŸ“„ Licence
Ce projet est sous licence **MIT**. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.
